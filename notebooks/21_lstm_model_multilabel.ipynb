{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM model\n",
    "\n",
    "## Architecture\n",
    "\n",
    "Many-to-many\n",
    "\n",
    "## DataSet implementation\n",
    "\n",
    "- Index is ticker based (create dictionary)\n",
    "- Analysis on padding\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuration parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRANSFORMED_DATA_FN = \"../data/transformed/data.csv\" # Data\n",
    "TRANSFORMED_META_FN = \"../data/transformed/data.json\" # Metadata\n",
    "\n",
    "MAX_SEQ_LENGTH = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_style(\"whitegrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = pd.read_csv(TRANSFORMED_DATA_FN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert datetimes\n",
    "\n",
    "for col in ('calendardate', 'datekey', 'reportperiod', 'lastupdated'):\n",
    "    df_1[col] = pd.to_datetime(df_1[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2 = df_1.sort_values(by=['ticker', 'datekey'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticker</th>\n",
       "      <th>exchange</th>\n",
       "      <th>siccode</th>\n",
       "      <th>dimension</th>\n",
       "      <th>calendardate</th>\n",
       "      <th>datekey</th>\n",
       "      <th>reportperiod</th>\n",
       "      <th>lastupdated</th>\n",
       "      <th>accoci</th>\n",
       "      <th>assets</th>\n",
       "      <th>...</th>\n",
       "      <th>sps</th>\n",
       "      <th>tangibles</th>\n",
       "      <th>taxassets</th>\n",
       "      <th>taxexp</th>\n",
       "      <th>taxliabilities</th>\n",
       "      <th>tbvps</th>\n",
       "      <th>workingcapital</th>\n",
       "      <th>price_shifted</th>\n",
       "      <th>pct_change_shifted</th>\n",
       "      <th>class1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>NYSE</td>\n",
       "      <td>3826.0</td>\n",
       "      <td>ART</td>\n",
       "      <td>2014-03-31</td>\n",
       "      <td>2014-06-04</td>\n",
       "      <td>2014-04-30</td>\n",
       "      <td>2019-08-30</td>\n",
       "      <td>132000000.0</td>\n",
       "      <td>1.102600e+10</td>\n",
       "      <td>...</td>\n",
       "      <td>20.360</td>\n",
       "      <td>7.134000e+09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>130000000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.423</td>\n",
       "      <td>3.658000e+09</td>\n",
       "      <td>58.07</td>\n",
       "      <td>0.010792</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A</td>\n",
       "      <td>NYSE</td>\n",
       "      <td>3826.0</td>\n",
       "      <td>ART</td>\n",
       "      <td>2014-06-30</td>\n",
       "      <td>2014-09-02</td>\n",
       "      <td>2014-07-31</td>\n",
       "      <td>2019-08-30</td>\n",
       "      <td>53000000.0</td>\n",
       "      <td>1.038000e+10</td>\n",
       "      <td>...</td>\n",
       "      <td>20.641</td>\n",
       "      <td>6.610000e+09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>123000000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.790</td>\n",
       "      <td>3.255000e+09</td>\n",
       "      <td>41.88</td>\n",
       "      <td>-0.278801</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A</td>\n",
       "      <td>NYSE</td>\n",
       "      <td>3826.0</td>\n",
       "      <td>ART</td>\n",
       "      <td>2014-09-30</td>\n",
       "      <td>2014-12-22</td>\n",
       "      <td>2014-10-31</td>\n",
       "      <td>2019-08-30</td>\n",
       "      <td>-334000000.0</td>\n",
       "      <td>1.083100e+10</td>\n",
       "      <td>...</td>\n",
       "      <td>20.964</td>\n",
       "      <td>7.265000e+09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>142000000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.817</td>\n",
       "      <td>3.798000e+09</td>\n",
       "      <td>40.63</td>\n",
       "      <td>-0.029847</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A</td>\n",
       "      <td>NYSE</td>\n",
       "      <td>3826.0</td>\n",
       "      <td>ART</td>\n",
       "      <td>2014-12-31</td>\n",
       "      <td>2015-03-10</td>\n",
       "      <td>2015-01-31</td>\n",
       "      <td>2019-08-30</td>\n",
       "      <td>-261000000.0</td>\n",
       "      <td>7.519000e+09</td>\n",
       "      <td>...</td>\n",
       "      <td>18.833</td>\n",
       "      <td>4.608000e+09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>157000000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.714</td>\n",
       "      <td>2.726000e+09</td>\n",
       "      <td>40.31</td>\n",
       "      <td>-0.007876</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A</td>\n",
       "      <td>NYSE</td>\n",
       "      <td>3826.0</td>\n",
       "      <td>ART</td>\n",
       "      <td>2015-03-31</td>\n",
       "      <td>2015-06-05</td>\n",
       "      <td>2015-04-30</td>\n",
       "      <td>2019-08-30</td>\n",
       "      <td>-270000000.0</td>\n",
       "      <td>7.412000e+09</td>\n",
       "      <td>...</td>\n",
       "      <td>16.647</td>\n",
       "      <td>4.555000e+09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>118000000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.638</td>\n",
       "      <td>2.690000e+09</td>\n",
       "      <td>35.53</td>\n",
       "      <td>-0.118581</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 116 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  ticker exchange  siccode dimension calendardate    datekey reportperiod  \\\n",
       "0      A     NYSE   3826.0       ART   2014-03-31 2014-06-04   2014-04-30   \n",
       "1      A     NYSE   3826.0       ART   2014-06-30 2014-09-02   2014-07-31   \n",
       "2      A     NYSE   3826.0       ART   2014-09-30 2014-12-22   2014-10-31   \n",
       "3      A     NYSE   3826.0       ART   2014-12-31 2015-03-10   2015-01-31   \n",
       "4      A     NYSE   3826.0       ART   2015-03-31 2015-06-05   2015-04-30   \n",
       "\n",
       "  lastupdated       accoci        assets  ...     sps     tangibles  \\\n",
       "0  2019-08-30  132000000.0  1.102600e+10  ...  20.360  7.134000e+09   \n",
       "1  2019-08-30   53000000.0  1.038000e+10  ...  20.641  6.610000e+09   \n",
       "2  2019-08-30 -334000000.0  1.083100e+10  ...  20.964  7.265000e+09   \n",
       "3  2019-08-30 -261000000.0  7.519000e+09  ...  18.833  4.608000e+09   \n",
       "4  2019-08-30 -270000000.0  7.412000e+09  ...  16.647  4.555000e+09   \n",
       "\n",
       "   taxassets       taxexp  taxliabilities   tbvps  workingcapital  \\\n",
       "0        0.0  130000000.0             0.0  21.423    3.658000e+09   \n",
       "1        0.0  123000000.0             0.0  19.790    3.255000e+09   \n",
       "2        0.0  142000000.0             0.0  21.817    3.798000e+09   \n",
       "3        0.0  157000000.0             0.0  13.714    2.726000e+09   \n",
       "4        0.0  118000000.0             0.0  13.638    2.690000e+09   \n",
       "\n",
       "   price_shifted  pct_change_shifted  class1  \n",
       "0          58.07            0.010792       0  \n",
       "1          41.88           -0.278801       0  \n",
       "2          40.63           -0.029847       0  \n",
       "3          40.31           -0.007876       0  \n",
       "4          35.53           -0.118581       0  \n",
       "\n",
       "[5 rows x 116 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = (df_2['pct_change_shifted']>-0.3) & (df_2['pct_change_shifted']<0)\n",
    "df_2.loc[mask,'class1'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = (df_2['pct_change_shifted']>0) & (df_2['pct_change_shifted']<0.3)\n",
    "df_2.loc[mask,'class1'] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = (df_2['pct_change_shifted']>0.3)\n",
    "df_2.loc[mask,'class1'] = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_2.fillna(-1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticker</th>\n",
       "      <th>exchange</th>\n",
       "      <th>siccode</th>\n",
       "      <th>dimension</th>\n",
       "      <th>calendardate</th>\n",
       "      <th>datekey</th>\n",
       "      <th>reportperiod</th>\n",
       "      <th>lastupdated</th>\n",
       "      <th>accoci</th>\n",
       "      <th>assets</th>\n",
       "      <th>...</th>\n",
       "      <th>sps</th>\n",
       "      <th>tangibles</th>\n",
       "      <th>taxassets</th>\n",
       "      <th>taxexp</th>\n",
       "      <th>taxliabilities</th>\n",
       "      <th>tbvps</th>\n",
       "      <th>workingcapital</th>\n",
       "      <th>price_shifted</th>\n",
       "      <th>pct_change_shifted</th>\n",
       "      <th>class1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>NYSE</td>\n",
       "      <td>3826.0</td>\n",
       "      <td>ART</td>\n",
       "      <td>2014-03-31</td>\n",
       "      <td>2014-06-04</td>\n",
       "      <td>2014-04-30</td>\n",
       "      <td>2019-08-30</td>\n",
       "      <td>132000000.0</td>\n",
       "      <td>1.102600e+10</td>\n",
       "      <td>...</td>\n",
       "      <td>20.360</td>\n",
       "      <td>7.134000e+09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>130000000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.423</td>\n",
       "      <td>3.658000e+09</td>\n",
       "      <td>58.07</td>\n",
       "      <td>0.010792</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A</td>\n",
       "      <td>NYSE</td>\n",
       "      <td>3826.0</td>\n",
       "      <td>ART</td>\n",
       "      <td>2014-06-30</td>\n",
       "      <td>2014-09-02</td>\n",
       "      <td>2014-07-31</td>\n",
       "      <td>2019-08-30</td>\n",
       "      <td>53000000.0</td>\n",
       "      <td>1.038000e+10</td>\n",
       "      <td>...</td>\n",
       "      <td>20.641</td>\n",
       "      <td>6.610000e+09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>123000000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.790</td>\n",
       "      <td>3.255000e+09</td>\n",
       "      <td>41.88</td>\n",
       "      <td>-0.278801</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A</td>\n",
       "      <td>NYSE</td>\n",
       "      <td>3826.0</td>\n",
       "      <td>ART</td>\n",
       "      <td>2014-09-30</td>\n",
       "      <td>2014-12-22</td>\n",
       "      <td>2014-10-31</td>\n",
       "      <td>2019-08-30</td>\n",
       "      <td>-334000000.0</td>\n",
       "      <td>1.083100e+10</td>\n",
       "      <td>...</td>\n",
       "      <td>20.964</td>\n",
       "      <td>7.265000e+09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>142000000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.817</td>\n",
       "      <td>3.798000e+09</td>\n",
       "      <td>40.63</td>\n",
       "      <td>-0.029847</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A</td>\n",
       "      <td>NYSE</td>\n",
       "      <td>3826.0</td>\n",
       "      <td>ART</td>\n",
       "      <td>2014-12-31</td>\n",
       "      <td>2015-03-10</td>\n",
       "      <td>2015-01-31</td>\n",
       "      <td>2019-08-30</td>\n",
       "      <td>-261000000.0</td>\n",
       "      <td>7.519000e+09</td>\n",
       "      <td>...</td>\n",
       "      <td>18.833</td>\n",
       "      <td>4.608000e+09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>157000000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.714</td>\n",
       "      <td>2.726000e+09</td>\n",
       "      <td>40.31</td>\n",
       "      <td>-0.007876</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A</td>\n",
       "      <td>NYSE</td>\n",
       "      <td>3826.0</td>\n",
       "      <td>ART</td>\n",
       "      <td>2015-03-31</td>\n",
       "      <td>2015-06-05</td>\n",
       "      <td>2015-04-30</td>\n",
       "      <td>2019-08-30</td>\n",
       "      <td>-270000000.0</td>\n",
       "      <td>7.412000e+09</td>\n",
       "      <td>...</td>\n",
       "      <td>16.647</td>\n",
       "      <td>4.555000e+09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>118000000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.638</td>\n",
       "      <td>2.690000e+09</td>\n",
       "      <td>35.53</td>\n",
       "      <td>-0.118581</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 116 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  ticker exchange  siccode dimension calendardate    datekey reportperiod  \\\n",
       "0      A     NYSE   3826.0       ART   2014-03-31 2014-06-04   2014-04-30   \n",
       "1      A     NYSE   3826.0       ART   2014-06-30 2014-09-02   2014-07-31   \n",
       "2      A     NYSE   3826.0       ART   2014-09-30 2014-12-22   2014-10-31   \n",
       "3      A     NYSE   3826.0       ART   2014-12-31 2015-03-10   2015-01-31   \n",
       "4      A     NYSE   3826.0       ART   2015-03-31 2015-06-05   2015-04-30   \n",
       "\n",
       "  lastupdated       accoci        assets  ...     sps     tangibles  \\\n",
       "0  2019-08-30  132000000.0  1.102600e+10  ...  20.360  7.134000e+09   \n",
       "1  2019-08-30   53000000.0  1.038000e+10  ...  20.641  6.610000e+09   \n",
       "2  2019-08-30 -334000000.0  1.083100e+10  ...  20.964  7.265000e+09   \n",
       "3  2019-08-30 -261000000.0  7.519000e+09  ...  18.833  4.608000e+09   \n",
       "4  2019-08-30 -270000000.0  7.412000e+09  ...  16.647  4.555000e+09   \n",
       "\n",
       "   taxassets       taxexp  taxliabilities   tbvps  workingcapital  \\\n",
       "0        0.0  130000000.0             0.0  21.423    3.658000e+09   \n",
       "1        0.0  123000000.0             0.0  19.790    3.255000e+09   \n",
       "2        0.0  142000000.0             0.0  21.817    3.798000e+09   \n",
       "3        0.0  157000000.0             0.0  13.714    2.726000e+09   \n",
       "4        0.0  118000000.0             0.0  13.638    2.690000e+09   \n",
       "\n",
       "   price_shifted  pct_change_shifted  class1  \n",
       "0          58.07            0.010792       2  \n",
       "1          41.88           -0.278801       1  \n",
       "2          40.63           -0.029847       1  \n",
       "3          40.31           -0.007876       1  \n",
       "4          35.53           -0.118581       1  \n",
       "\n",
       "[5 rows x 116 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filter_mask = (df_2['marketcap']>1000000.0) & (df_2['netmargin'] > -0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_2 = df_2.loc[filter_mask,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Break down the temporal chains\n",
    "\n",
    "tickers = df_2['ticker'].values\n",
    "max_count = MAX_SEQ_LENGTH\n",
    "\n",
    "prev_ticker = tickers[0]\n",
    "output_tickers = [prev_ticker+\"_0\"]\n",
    "counter = 0\n",
    "append_index = 0\n",
    "\n",
    "for ticker in tickers[1:]:\n",
    "    if ticker == prev_ticker:\n",
    "        counter +=1        \n",
    "    else:\n",
    "        counter = 0\n",
    "        append_index = 0\n",
    "    if counter == max_count:\n",
    "        counter = 0\n",
    "        append_index +=1\n",
    "    output_tickers.append(ticker+\"_{}\".format(append_index))\n",
    "    prev_ticker = ticker\n",
    "    \n",
    "assert len(output_tickers) == len(tickers)\n",
    "output_tickers[:22]\n",
    "tickers[:22]\n",
    "\n",
    "df_2['ticker'] = output_tickers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(TRANSFORMED_META_FN, 'r') as fp:\n",
    "    metadata = json.load(fp)\n",
    "    \n",
    "features = metadata['features'].split(\",\")\n",
    "target = metadata['target']\n",
    "#target='pct_change_shifted'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [ 'assets', 'assetsavg', 'assetsc',\n",
    "       'assetsnc', 'assetturnover', 'bvps', 'capex', 'cashneq',\n",
    "       'cashnequsd', 'cor', 'consolinc', 'currentratio', 'de', 'debt',\n",
    "       'debtc', 'debtnc', 'debtusd', 'deferredrev', 'depamor', 'deposits',\n",
    "       'divyield', 'dps', 'ebit', 'ebitda', 'ebitdamargin', 'ebitdausd',\n",
    "       'ebitusd', 'ebt', 'eps', 'epsdil', 'epsusd', 'equity', 'equityavg',\n",
    "       'equityusd', 'ev', 'evebit', 'evebitda', 'fcf', 'fcfps', 'fxusd',\n",
    "       'gp', 'grossmargin', 'intangibles', 'intexp', 'invcap',\n",
    "       'invcapavg', 'inventory', 'investments', 'investmentsc',\n",
    "       'investmentsnc', 'liabilities', 'liabilitiesc', 'liabilitiesnc',\n",
    "       'marketcap', 'ncf', 'ncfbus', 'ncfcommon', 'ncfdebt', 'ncfdiv',\n",
    "       'ncff', 'ncfi', 'ncfinv', 'ncfo', 'ncfx', 'netinc', 'netinccmn',\n",
    "       'netinccmnusd', 'netincdis', 'netincnci', 'netmargin', 'opex',\n",
    "       'opinc', 'payables', 'payoutratio', 'pb', 'pe', 'pe1', 'ppnenet',\n",
    "       'prefdivis', 'price', 'ps', 'ps1', 'receivables', 'retearn',\n",
    "       'revenue', 'revenueusd', 'rnd', 'roa', 'roe', 'roic', 'ros',\n",
    "       'sbcomp', 'sgna', 'sharefactor', 'sharesbas', 'shareswa',\n",
    "       'shareswadil', 'sps', 'tangibles', 'taxassets', 'taxexp',\n",
    "       'taxliabilities', 'tbvps', 'workingcapital']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_lengths = df_2.groupby('ticker').count()['datekey'].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.distplot(seq_lengths, bins = 20);\n",
    "plt.title(\"Distribution of sequence lengths\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(seq_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum sequence length:  5\n"
     ]
    }
   ],
   "source": [
    "print(\"Maximum sequence length: \", max(seq_lengths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_padded_features(sorted_df, ticker, features, target, n_pad):\n",
    "    \"\"\" Return padded features and target\n",
    "    \n",
    "    Arguments\n",
    "    ---------\n",
    "    \n",
    "    sorted_df : Pandas dataframe\n",
    "        Dataframe with indicators, sorted by ticker and datekey        \n",
    "    ticker : str\n",
    "        Ticker name\n",
    "    features : list\n",
    "        Feature names        \n",
    "    target : str\n",
    "        Target name\n",
    "    pad : int\n",
    "        Pad length\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    padded_features : ndarray with shape (n_pad, n_features)\n",
    "    target : ndarray with shape (n_pad,1)\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    n_features = len(features)\n",
    "    \n",
    "    ticker_data = sorted_df.loc[sorted_df['ticker'] == ticker, :]\n",
    "    \n",
    "    ticker_features = ticker_data.loc[:, features]\n",
    "    ticker_target = ticker_data.loc[:, target]\n",
    "    \n",
    "    out_features = np.zeros((n_pad, n_features))\n",
    "    out_target = np.zeros((n_pad, 1))\n",
    "    \n",
    "    out_features[0:len(ticker_features)] = ticker_features.values\n",
    "    out_target[0:len(ticker_features)] = ticker_target.values.reshape(-1,1)\n",
    "    \n",
    "    return out_features, out_target, len(ticker_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_array, target_array, len_ticker = get_padded_features(df_2, ticker='GEN', features = features, target = target, n_pad = MAX_SEQ_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5, 104), (5, 1))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_array.shape, target_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create unique ticker list and shuffle\n",
    "\n",
    "all_tickers = df_2['ticker'].unique()\n",
    "np.random.shuffle(all_tickers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20447"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_2['ticker'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TickersIndicatorsDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Tickers Indicators Dataset\n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self, indicators_df, feature_names, target_name, n_pad):\n",
    "        \n",
    "        self.df = indicators_df.sort_values(by=['ticker', 'datekey'])\n",
    "        self.target = target_name\n",
    "        self.features = feature_names\n",
    "        self.ticker_list = self.df['ticker'].unique()\n",
    "        self.n_pad = n_pad\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.ticker_list)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        ticker = self.ticker_list[idx]\n",
    "        X, y, len_ticker = get_padded_features(self.df, ticker=ticker, features = self.features, target = self.target, n_pad = self.n_pad)\n",
    "        \n",
    "        return torch.from_numpy(X).float(),  torch.tensor(y, dtype=torch.long), len_ticker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "td = TickersIndicatorsDataset(df_2, features, target, MAX_SEQ_LENGTH )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20447"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(td)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-processing\n",
    "\n",
    "Scaling and imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import Imputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ratio = 0.5\n",
    "\n",
    "test_idx = int(len(all_tickers)*test_ratio)\n",
    "test_idx = 3000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tickers = all_tickers[:test_idx]\n",
    "test_tickers = all_tickers[test_idx:test_idx+test_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_all = df_2[df_2['ticker'].isin(train_tickers)]\n",
    "df_test_all = df_2[df_2['ticker'].isin(test_tickers)]\n",
    "\n",
    "df_train = df_train_all[features]\n",
    "df_test = df_test_all[features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imputation\n",
    "\n",
    "imputer = Imputer(missing_values = 'NaN', strategy = 'mean', axis = 0)\n",
    "imputer = imputer.fit(df_train)\n",
    "\n",
    "df_train_imp = pd.DataFrame(imputer.transform(df_train))\n",
    "df_train_imp.columns = df_train.columns\n",
    "df_train_imp.index = df_train.index\n",
    "\n",
    "df_test_imp = pd.DataFrame(imputer.transform(df_test))\n",
    "df_test_imp.columns = df_test.columns\n",
    "df_test_imp.index = df_test.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Imputer(axis=0, copy=True, missing_values='NaN', strategy='mean', verbose=0)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaler\n",
    "\n",
    "scaler = preprocessing.StandardScaler().fit(df_train_imp)\n",
    "\n",
    "cols, idx = df_train_imp.columns, df_train_imp.index\n",
    "df_train_imp = pd.DataFrame(scaler.transform(df_train_imp))\n",
    "df_train_imp.columns = cols\n",
    "df_train_imp.index = idx\n",
    "\n",
    "cols, idx = df_test_imp.columns, df_test_imp.index\n",
    "df_test_imp = pd.DataFrame(scaler.transform(df_test_imp))\n",
    "df_test_imp.columns = cols\n",
    "df_test_imp.index = idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_cols = ['ticker', 'datekey',target]\n",
    "\n",
    "df_train_imp[meta_cols] = df_train_all[meta_cols]\n",
    "df_test_imp[meta_cols] = df_test_all[meta_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>assets</th>\n",
       "      <th>assetsavg</th>\n",
       "      <th>assetsc</th>\n",
       "      <th>assetsnc</th>\n",
       "      <th>assetturnover</th>\n",
       "      <th>bvps</th>\n",
       "      <th>capex</th>\n",
       "      <th>cashneq</th>\n",
       "      <th>cashnequsd</th>\n",
       "      <th>cor</th>\n",
       "      <th>...</th>\n",
       "      <th>shareswa</th>\n",
       "      <th>shareswadil</th>\n",
       "      <th>sps</th>\n",
       "      <th>tangibles</th>\n",
       "      <th>taxassets</th>\n",
       "      <th>taxexp</th>\n",
       "      <th>taxliabilities</th>\n",
       "      <th>tbvps</th>\n",
       "      <th>workingcapital</th>\n",
       "      <th>class1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.252700e+04</td>\n",
       "      <td>1.252700e+04</td>\n",
       "      <td>1.252700e+04</td>\n",
       "      <td>1.252700e+04</td>\n",
       "      <td>1.252700e+04</td>\n",
       "      <td>1.252700e+04</td>\n",
       "      <td>1.252700e+04</td>\n",
       "      <td>1.252700e+04</td>\n",
       "      <td>1.252700e+04</td>\n",
       "      <td>1.252700e+04</td>\n",
       "      <td>...</td>\n",
       "      <td>1.252700e+04</td>\n",
       "      <td>1.252700e+04</td>\n",
       "      <td>1.252700e+04</td>\n",
       "      <td>1.252700e+04</td>\n",
       "      <td>1.252700e+04</td>\n",
       "      <td>1.252700e+04</td>\n",
       "      <td>1.252700e+04</td>\n",
       "      <td>1.252700e+04</td>\n",
       "      <td>1.252700e+04</td>\n",
       "      <td>12527.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>9.142922e-18</td>\n",
       "      <td>-2.640956e-17</td>\n",
       "      <td>3.605987e-18</td>\n",
       "      <td>-3.337892e-18</td>\n",
       "      <td>-7.357764e-17</td>\n",
       "      <td>-1.173497e-17</td>\n",
       "      <td>-6.821464e-18</td>\n",
       "      <td>5.166809e-17</td>\n",
       "      <td>6.144358e-17</td>\n",
       "      <td>5.683883e-16</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.692360e-17</td>\n",
       "      <td>2.636636e-18</td>\n",
       "      <td>2.195539e-17</td>\n",
       "      <td>-9.077782e-17</td>\n",
       "      <td>1.904942e-16</td>\n",
       "      <td>-1.063157e-16</td>\n",
       "      <td>-1.610238e-15</td>\n",
       "      <td>-2.928438e-17</td>\n",
       "      <td>4.793830e-17</td>\n",
       "      <td>1.506745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.000040e+00</td>\n",
       "      <td>1.000040e+00</td>\n",
       "      <td>1.000040e+00</td>\n",
       "      <td>1.000040e+00</td>\n",
       "      <td>1.000040e+00</td>\n",
       "      <td>1.000040e+00</td>\n",
       "      <td>1.000040e+00</td>\n",
       "      <td>1.000040e+00</td>\n",
       "      <td>1.000040e+00</td>\n",
       "      <td>1.000040e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000040e+00</td>\n",
       "      <td>1.000040e+00</td>\n",
       "      <td>1.000040e+00</td>\n",
       "      <td>1.000040e+00</td>\n",
       "      <td>1.000040e+00</td>\n",
       "      <td>1.000040e+00</td>\n",
       "      <td>1.000040e+00</td>\n",
       "      <td>1.000040e+00</td>\n",
       "      <td>1.000040e+00</td>\n",
       "      <td>0.720427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-4.031922e-02</td>\n",
       "      <td>-4.188254e-02</td>\n",
       "      <td>-4.183075e-02</td>\n",
       "      <td>-3.456286e-02</td>\n",
       "      <td>-4.409906e+01</td>\n",
       "      <td>-9.423111e+01</td>\n",
       "      <td>-7.462565e+01</td>\n",
       "      <td>-3.407888e-02</td>\n",
       "      <td>-8.291321e-02</td>\n",
       "      <td>-2.967368e-02</td>\n",
       "      <td>...</td>\n",
       "      <td>-6.721799e-02</td>\n",
       "      <td>-2.452663e-01</td>\n",
       "      <td>-1.159258e-02</td>\n",
       "      <td>-4.003073e-02</td>\n",
       "      <td>-1.996163e-02</td>\n",
       "      <td>-3.088744e+00</td>\n",
       "      <td>-2.596530e-02</td>\n",
       "      <td>-1.574366e-02</td>\n",
       "      <td>-1.116913e+01</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-4.029610e-02</td>\n",
       "      <td>-4.185666e-02</td>\n",
       "      <td>-4.157976e-02</td>\n",
       "      <td>-3.451255e-02</td>\n",
       "      <td>-5.196942e-01</td>\n",
       "      <td>1.450664e-02</td>\n",
       "      <td>2.497343e-02</td>\n",
       "      <td>-3.406511e-02</td>\n",
       "      <td>-8.162972e-02</td>\n",
       "      <td>-2.935523e-02</td>\n",
       "      <td>...</td>\n",
       "      <td>-6.202273e-02</td>\n",
       "      <td>-2.019159e-01</td>\n",
       "      <td>-1.157782e-02</td>\n",
       "      <td>-4.001173e-02</td>\n",
       "      <td>-1.996163e-02</td>\n",
       "      <td>-2.520840e-02</td>\n",
       "      <td>-2.596510e-02</td>\n",
       "      <td>-1.574337e-02</td>\n",
       "      <td>-2.878820e-02</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-4.020380e-02</td>\n",
       "      <td>-4.175358e-02</td>\n",
       "      <td>-4.058244e-02</td>\n",
       "      <td>-3.396732e-02</td>\n",
       "      <td>-1.259239e-01</td>\n",
       "      <td>1.450676e-02</td>\n",
       "      <td>2.554440e-02</td>\n",
       "      <td>-3.402900e-02</td>\n",
       "      <td>-7.826818e-02</td>\n",
       "      <td>-2.909112e-02</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.461155e-02</td>\n",
       "      <td>-1.209156e-01</td>\n",
       "      <td>-1.157585e-02</td>\n",
       "      <td>-3.994424e-02</td>\n",
       "      <td>-1.996163e-02</td>\n",
       "      <td>-2.515613e-02</td>\n",
       "      <td>-2.596484e-02</td>\n",
       "      <td>-1.574282e-02</td>\n",
       "      <td>-2.705252e-02</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>-3.987770e-02</td>\n",
       "      <td>-4.134727e-02</td>\n",
       "      <td>-5.011124e-03</td>\n",
       "      <td>-1.128701e-02</td>\n",
       "      <td>2.523866e-01</td>\n",
       "      <td>1.450692e-02</td>\n",
       "      <td>2.562659e-02</td>\n",
       "      <td>-3.389949e-02</td>\n",
       "      <td>-6.639468e-02</td>\n",
       "      <td>-2.744218e-02</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.613819e-02</td>\n",
       "      <td>5.399332e-17</td>\n",
       "      <td>-1.157011e-02</td>\n",
       "      <td>-3.969012e-02</td>\n",
       "      <td>-1.984570e-02</td>\n",
       "      <td>-2.465079e-02</td>\n",
       "      <td>-2.559589e-02</td>\n",
       "      <td>-1.574151e-02</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4.460924e+01</td>\n",
       "      <td>4.299224e+01</td>\n",
       "      <td>5.395607e+01</td>\n",
       "      <td>5.926413e+01</td>\n",
       "      <td>1.704355e+01</td>\n",
       "      <td>1.603162e-02</td>\n",
       "      <td>4.332681e-02</td>\n",
       "      <td>5.560172e+01</td>\n",
       "      <td>4.713711e+01</td>\n",
       "      <td>5.908483e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>1.038376e+02</td>\n",
       "      <td>7.424648e+01</td>\n",
       "      <td>1.087047e+02</td>\n",
       "      <td>4.450874e+01</td>\n",
       "      <td>9.244794e+01</td>\n",
       "      <td>6.966516e+01</td>\n",
       "      <td>8.777293e+01</td>\n",
       "      <td>7.256569e+01</td>\n",
       "      <td>7.105251e+01</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 105 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             assets     assetsavg       assetsc      assetsnc  assetturnover  \\\n",
       "count  1.252700e+04  1.252700e+04  1.252700e+04  1.252700e+04   1.252700e+04   \n",
       "mean   9.142922e-18 -2.640956e-17  3.605987e-18 -3.337892e-18  -7.357764e-17   \n",
       "std    1.000040e+00  1.000040e+00  1.000040e+00  1.000040e+00   1.000040e+00   \n",
       "min   -4.031922e-02 -4.188254e-02 -4.183075e-02 -3.456286e-02  -4.409906e+01   \n",
       "25%   -4.029610e-02 -4.185666e-02 -4.157976e-02 -3.451255e-02  -5.196942e-01   \n",
       "50%   -4.020380e-02 -4.175358e-02 -4.058244e-02 -3.396732e-02  -1.259239e-01   \n",
       "75%   -3.987770e-02 -4.134727e-02 -5.011124e-03 -1.128701e-02   2.523866e-01   \n",
       "max    4.460924e+01  4.299224e+01  5.395607e+01  5.926413e+01   1.704355e+01   \n",
       "\n",
       "               bvps         capex       cashneq    cashnequsd           cor  \\\n",
       "count  1.252700e+04  1.252700e+04  1.252700e+04  1.252700e+04  1.252700e+04   \n",
       "mean  -1.173497e-17 -6.821464e-18  5.166809e-17  6.144358e-17  5.683883e-16   \n",
       "std    1.000040e+00  1.000040e+00  1.000040e+00  1.000040e+00  1.000040e+00   \n",
       "min   -9.423111e+01 -7.462565e+01 -3.407888e-02 -8.291321e-02 -2.967368e-02   \n",
       "25%    1.450664e-02  2.497343e-02 -3.406511e-02 -8.162972e-02 -2.935523e-02   \n",
       "50%    1.450676e-02  2.554440e-02 -3.402900e-02 -7.826818e-02 -2.909112e-02   \n",
       "75%    1.450692e-02  2.562659e-02 -3.389949e-02 -6.639468e-02 -2.744218e-02   \n",
       "max    1.603162e-02  4.332681e-02  5.560172e+01  4.713711e+01  5.908483e+01   \n",
       "\n",
       "       ...      shareswa   shareswadil           sps     tangibles  \\\n",
       "count  ...  1.252700e+04  1.252700e+04  1.252700e+04  1.252700e+04   \n",
       "mean   ... -2.692360e-17  2.636636e-18  2.195539e-17 -9.077782e-17   \n",
       "std    ...  1.000040e+00  1.000040e+00  1.000040e+00  1.000040e+00   \n",
       "min    ... -6.721799e-02 -2.452663e-01 -1.159258e-02 -4.003073e-02   \n",
       "25%    ... -6.202273e-02 -2.019159e-01 -1.157782e-02 -4.001173e-02   \n",
       "50%    ... -5.461155e-02 -1.209156e-01 -1.157585e-02 -3.994424e-02   \n",
       "75%    ... -3.613819e-02  5.399332e-17 -1.157011e-02 -3.969012e-02   \n",
       "max    ...  1.038376e+02  7.424648e+01  1.087047e+02  4.450874e+01   \n",
       "\n",
       "          taxassets        taxexp  taxliabilities         tbvps  \\\n",
       "count  1.252700e+04  1.252700e+04    1.252700e+04  1.252700e+04   \n",
       "mean   1.904942e-16 -1.063157e-16   -1.610238e-15 -2.928438e-17   \n",
       "std    1.000040e+00  1.000040e+00    1.000040e+00  1.000040e+00   \n",
       "min   -1.996163e-02 -3.088744e+00   -2.596530e-02 -1.574366e-02   \n",
       "25%   -1.996163e-02 -2.520840e-02   -2.596510e-02 -1.574337e-02   \n",
       "50%   -1.996163e-02 -2.515613e-02   -2.596484e-02 -1.574282e-02   \n",
       "75%   -1.984570e-02 -2.465079e-02   -2.559589e-02 -1.574151e-02   \n",
       "max    9.244794e+01  6.966516e+01    8.777293e+01  7.256569e+01   \n",
       "\n",
       "       workingcapital        class1  \n",
       "count    1.252700e+04  12527.000000  \n",
       "mean     4.793830e-17      1.506745  \n",
       "std      1.000040e+00      0.720427  \n",
       "min     -1.116913e+01      0.000000  \n",
       "25%     -2.878820e-02      1.000000  \n",
       "50%     -2.705252e-02      2.000000  \n",
       "75%      0.000000e+00      2.000000  \n",
       "max      7.105251e+01      3.000000  \n",
       "\n",
       "[8 rows x 105 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_imp.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12527, 107)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_imp.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    \n",
    "    def __init__(self, feature_size, n_activation = 15):\n",
    "        super(Model, self).__init__()\n",
    "        \n",
    "        self.n_activation = n_activation\n",
    "        \n",
    "        # LSTM parameters - input feature size X, number of units in hidden layer.\n",
    "        \n",
    "        self.lstm = nn.LSTM(feature_size, n_activation, batch_first=True)\n",
    "        self.linear2 = nn.Linear(n_activation, 5)\n",
    "        self.out = nn.Linear(5, 1)\n",
    "        self.out2 = nn.Linear(n_activation, 4)\n",
    "    \n",
    "    def forward(self, x, lenx):\n",
    "        \n",
    "        # x has dimension of [batch_size, sequence size]       \n",
    "        \n",
    "        # Here h_lstm contains hidden activations from all sequences, dimension: [batch_size, seq_size, n_activation]\n",
    "        x_packed = torch.nn.utils.rnn.pack_padded_sequence(x, batch_first=True, lengths=lenx, enforce_sorted=False)\n",
    "        \n",
    "        h_lstm, (h_n, c_n) = self.lstm(x_packed)\n",
    "        #layer2 = torch.relu(self.linear2(h_lstm))\n",
    "        #out = self.out2(h_lstm)\n",
    "        padded_output, output_lens = torch.nn.utils.rnn.pad_packed_sequence(h_lstm, batch_first=True, total_length=MAX_SEQ_LENGTH)\n",
    "#         layer2 = torch.relu(self.linear2(padded_output))\n",
    "        #out = torch.sigmoid(self.out2(padded_output))\n",
    "        out = self.out2(padded_output)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12527"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_imp.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(feature_size=df_train.shape[1]).cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "weight_decay=0.00001\n",
    "batch_size = 200\n",
    "n_epoch = 200\n",
    "\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = TickersIndicatorsDataset(df_train_imp, features, target, MAX_SEQ_LENGTH )\n",
    "x_test = TickersIndicatorsDataset(df_test_imp, features, target, MAX_SEQ_LENGTH )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(x_train, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = DataLoader(x_test, batch_size=len(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### DEBUG test\n",
    "\n",
    "# sample_data, sample_target, lenx = next(iter(train_loader))\n",
    "\n",
    "# print(sample_data.shape, sample_target.shape)\n",
    "\n",
    "# # Feed sample data\n",
    "# out = model(sample_data.float(), lenx)\n",
    "\n",
    "# out.shape\n",
    "\n",
    "# sample_data.shape\n",
    "\n",
    "# sample_target.shape\n",
    "\n",
    "# #out.view(batch_size,-1).shape\n",
    "\n",
    "# sample_target.view(-1, 1).shape\n",
    "\n",
    "# loss = loss_function(out, sample_target.view(batch_size, -1))\n",
    "# print(loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def calc_auc(model, dataloader):\n",
    "#     model.eval()\n",
    "#     roc_list = []\n",
    "#     for data_i, target_i, len_i in dataloader:\n",
    "#         y_pred = model(data_i, len_i).detach().squeeze().reshape(-1,1).numpy()\n",
    "#         y_true = target_i.detach().squeeze().reshape(-1,1).numpy()\n",
    "#         roc_list.append(roc_auc_score(y_true, y_pred))\n",
    "#     return np.average(roc_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def calc_loss(output_padded, y):\n",
    "#     batch_ce_loss = 0.0\n",
    "#     for i in range(output_padded.size(0)):\n",
    "#       ce_loss = F.binary_cross_entropy(output_padded[i], y[i].view(-1,4), reduction=\"sum\")\n",
    "#       batch_ce_loss += ce_loss\n",
    "#     return batch_ce_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Train loss: 1.425561547279358, Validation loss: 1.4192315340042114, Validation acc: 0.08293333333333333\n",
      "Epoch: 1, Train loss: 1.385451316833496, Validation loss: 1.3806986808776855, Validation acc: 0.29873333333333335\n",
      "Epoch: 2, Train loss: 1.3411930799484253, Validation loss: 1.337923526763916, Validation acc: 0.3702\n",
      "Epoch: 3, Train loss: 1.2917449474334717, Validation loss: 1.2901521921157837, Validation acc: 0.37646666666666667\n",
      "Epoch: 4, Train loss: 1.2434983253479004, Validation loss: 1.2442094087600708, Validation acc: 0.3784\n",
      "Epoch: 5, Train loss: 1.2042781114578247, Validation loss: 1.2068440914154053, Validation acc: 0.3794666666666667\n",
      "Epoch: 6, Train loss: 1.17709481716156, Validation loss: 1.1807734966278076, Validation acc: 0.3812\n",
      "Epoch: 7, Train loss: 1.1613812446594238, Validation loss: 1.164945125579834, Validation acc: 0.3848\n",
      "Epoch: 8, Train loss: 1.1509822607040405, Validation loss: 1.1533653736114502, Validation acc: 0.3924\n",
      "Epoch: 9, Train loss: 1.1420507431030273, Validation loss: 1.142980933189392, Validation acc: 0.3907333333333333\n",
      "Epoch: 10, Train loss: 1.133819818496704, Validation loss: 1.133363962173462, Validation acc: 0.3930666666666667\n",
      "Epoch: 11, Train loss: 1.12616765499115, Validation loss: 1.1245272159576416, Validation acc: 0.5554666666666667\n",
      "Epoch: 12, Train loss: 1.1188758611679077, Validation loss: 1.116325855255127, Validation acc: 0.5563333333333333\n",
      "Epoch: 13, Train loss: 1.1120637655258179, Validation loss: 1.1088351011276245, Validation acc: 0.557\n",
      "Epoch: 14, Train loss: 1.1058515310287476, Validation loss: 1.102219581604004, Validation acc: 0.5586\n",
      "Epoch: 15, Train loss: 1.1002354621887207, Validation loss: 1.0963630676269531, Validation acc: 0.5596\n",
      "Epoch: 16, Train loss: 1.09517240524292, Validation loss: 1.0911495685577393, Validation acc: 0.5602666666666667\n",
      "Epoch: 17, Train loss: 1.0905357599258423, Validation loss: 1.086458683013916, Validation acc: 0.5603333333333333\n",
      "Epoch: 18, Train loss: 1.0862129926681519, Validation loss: 1.0821521282196045, Validation acc: 0.5606666666666666\n",
      "Epoch: 19, Train loss: 1.0821053981781006, Validation loss: 1.0782495737075806, Validation acc: 0.5602666666666667\n",
      "Epoch: 20, Train loss: 1.0781359672546387, Validation loss: 1.0744091272354126, Validation acc: 0.5605333333333333\n",
      "Epoch: 21, Train loss: 1.074280023574829, Validation loss: 1.070756196975708, Validation acc: 0.5616666666666666\n",
      "Epoch: 22, Train loss: 1.070518136024475, Validation loss: 1.0671286582946777, Validation acc: 0.562\n",
      "Epoch: 23, Train loss: 1.0668444633483887, Validation loss: 1.0636323690414429, Validation acc: 0.5628666666666666\n",
      "Epoch: 24, Train loss: 1.063251256942749, Validation loss: 1.060263752937317, Validation acc: 0.562\n",
      "Epoch: 25, Train loss: 1.059731125831604, Validation loss: 1.0570281744003296, Validation acc: 0.5634\n",
      "Epoch: 26, Train loss: 1.0562788248062134, Validation loss: 1.0537691116333008, Validation acc: 0.5632666666666667\n",
      "Epoch: 27, Train loss: 1.0528913736343384, Validation loss: 1.050620675086975, Validation acc: 0.5636666666666666\n",
      "Epoch: 28, Train loss: 1.0495524406433105, Validation loss: 1.047520399093628, Validation acc: 0.5646\n",
      "Epoch: 29, Train loss: 1.0462533235549927, Validation loss: 1.0444501638412476, Validation acc: 0.5653333333333334\n",
      "Epoch: 30, Train loss: 1.0430011749267578, Validation loss: 1.0414462089538574, Validation acc: 0.5645333333333333\n",
      "Epoch: 31, Train loss: 1.0398186445236206, Validation loss: 1.0385453701019287, Validation acc: 0.5643333333333334\n",
      "Epoch: 32, Train loss: 1.0367058515548706, Validation loss: 1.0357102155685425, Validation acc: 0.5651333333333334\n",
      "Epoch: 33, Train loss: 1.033664345741272, Validation loss: 1.0329045057296753, Validation acc: 0.5646\n",
      "Epoch: 34, Train loss: 1.0306965112686157, Validation loss: 1.0301345586776733, Validation acc: 0.5652\n",
      "Epoch: 35, Train loss: 1.027783989906311, Validation loss: 1.0274053812026978, Validation acc: 0.5652666666666667\n",
      "Epoch: 36, Train loss: 1.0249221324920654, Validation loss: 1.024762749671936, Validation acc: 0.5656\n",
      "Epoch: 37, Train loss: 1.022081732749939, Validation loss: 1.0221847295761108, Validation acc: 0.5654666666666667\n",
      "Epoch: 38, Train loss: 1.01926589012146, Validation loss: 1.0197181701660156, Validation acc: 0.5660666666666667\n",
      "Epoch: 39, Train loss: 1.0165026187896729, Validation loss: 1.017257809638977, Validation acc: 0.566\n",
      "Epoch: 40, Train loss: 1.013824224472046, Validation loss: 1.014790415763855, Validation acc: 0.5658666666666666\n",
      "Epoch: 41, Train loss: 1.0112180709838867, Validation loss: 1.012434720993042, Validation acc: 0.5658666666666666\n",
      "Epoch: 42, Train loss: 1.0086674690246582, Validation loss: 1.0100458860397339, Validation acc: 0.5660666666666667\n",
      "Epoch: 43, Train loss: 1.0061566829681396, Validation loss: 1.0077502727508545, Validation acc: 0.5664\n",
      "Epoch: 44, Train loss: 1.0036792755126953, Validation loss: 1.0054954290390015, Validation acc: 0.5662666666666667\n",
      "Epoch: 45, Train loss: 1.001261591911316, Validation loss: 1.0033491849899292, Validation acc: 0.5662\n",
      "Epoch: 46, Train loss: 0.9988927245140076, Validation loss: 1.0011574029922485, Validation acc: 0.5656\n",
      "Epoch: 47, Train loss: 0.9965622425079346, Validation loss: 0.9990512728691101, Validation acc: 0.5655333333333333\n",
      "Epoch: 48, Train loss: 0.9942770600318909, Validation loss: 0.9969882369041443, Validation acc: 0.5654\n",
      "Epoch: 49, Train loss: 0.9920371174812317, Validation loss: 0.9949486255645752, Validation acc: 0.5658666666666666\n",
      "Epoch: 50, Train loss: 0.9898342490196228, Validation loss: 0.9929094910621643, Validation acc: 0.5654\n",
      "Epoch: 51, Train loss: 0.9876766800880432, Validation loss: 0.9910025596618652, Validation acc: 0.5650666666666667\n",
      "Epoch: 52, Train loss: 0.9855512380599976, Validation loss: 0.989050567150116, Validation acc: 0.5651333333333334\n",
      "Epoch: 53, Train loss: 0.9834636449813843, Validation loss: 0.9872176647186279, Validation acc: 0.5648\n",
      "Epoch: 54, Train loss: 0.9814147353172302, Validation loss: 0.9853729009628296, Validation acc: 0.5654\n",
      "Epoch: 55, Train loss: 0.9793999791145325, Validation loss: 0.9835388660430908, Validation acc: 0.5643333333333334\n",
      "Epoch: 56, Train loss: 0.9774267077445984, Validation loss: 0.9817359447479248, Validation acc: 0.5646\n",
      "Epoch: 57, Train loss: 0.975489616394043, Validation loss: 0.9799886345863342, Validation acc: 0.5640666666666667\n",
      "Epoch: 58, Train loss: 0.9735874533653259, Validation loss: 0.9782319068908691, Validation acc: 0.5638\n",
      "Epoch: 59, Train loss: 0.9717205166816711, Validation loss: 0.976519763469696, Validation acc: 0.5646\n",
      "Epoch: 60, Train loss: 0.9698858857154846, Validation loss: 0.9748474359512329, Validation acc: 0.5646\n",
      "Epoch: 61, Train loss: 0.9680861830711365, Validation loss: 0.9732005596160889, Validation acc: 0.5643333333333334\n",
      "Epoch: 62, Train loss: 0.9663164019584656, Validation loss: 0.9716029167175293, Validation acc: 0.5644\n",
      "Epoch: 63, Train loss: 0.964573085308075, Validation loss: 0.9699168801307678, Validation acc: 0.5645333333333333\n",
      "Epoch: 64, Train loss: 0.9628592133522034, Validation loss: 0.9682911038398743, Validation acc: 0.5642666666666667\n",
      "Epoch: 65, Train loss: 0.9611685276031494, Validation loss: 0.9667374491691589, Validation acc: 0.5642666666666667\n",
      "Epoch: 66, Train loss: 0.9595099687576294, Validation loss: 0.9651433825492859, Validation acc: 0.5648\n",
      "Epoch: 67, Train loss: 0.9578826427459717, Validation loss: 0.9637057781219482, Validation acc: 0.5646\n",
      "Epoch: 68, Train loss: 0.9562837481498718, Validation loss: 0.9622331261634827, Validation acc: 0.5644666666666667\n",
      "Epoch: 69, Train loss: 0.9547101259231567, Validation loss: 0.9607551693916321, Validation acc: 0.5644\n",
      "Epoch: 70, Train loss: 0.9531748294830322, Validation loss: 0.9593867063522339, Validation acc: 0.5644666666666667\n",
      "Epoch: 71, Train loss: 0.9516698718070984, Validation loss: 0.9579439163208008, Validation acc: 0.5646666666666667\n",
      "Epoch: 72, Train loss: 0.9501954913139343, Validation loss: 0.9565938115119934, Validation acc: 0.5649333333333333\n",
      "Epoch: 73, Train loss: 0.9487547278404236, Validation loss: 0.9552524089813232, Validation acc: 0.5648666666666666\n",
      "Epoch: 74, Train loss: 0.9473369121551514, Validation loss: 0.9539196491241455, Validation acc: 0.5645333333333333\n",
      "Epoch: 75, Train loss: 0.9459481835365295, Validation loss: 0.9525995850563049, Validation acc: 0.5646666666666667\n",
      "Epoch: 76, Train loss: 0.9445830583572388, Validation loss: 0.9511388540267944, Validation acc: 0.5652666666666667\n",
      "Epoch: 77, Train loss: 0.9432433843612671, Validation loss: 0.9498752355575562, Validation acc: 0.5658\n",
      "Epoch: 78, Train loss: 0.9419200420379639, Validation loss: 0.9485905170440674, Validation acc: 0.5658666666666666\n",
      "Epoch: 79, Train loss: 0.9406147599220276, Validation loss: 0.9473981857299805, Validation acc: 0.5660666666666667\n",
      "Epoch: 80, Train loss: 0.9393338561058044, Validation loss: 0.9462347030639648, Validation acc: 0.566\n",
      "Epoch: 81, Train loss: 0.9380669593811035, Validation loss: 0.9450846910476685, Validation acc: 0.5656\n",
      "Epoch: 82, Train loss: 0.9368217587471008, Validation loss: 0.943938136100769, Validation acc: 0.5653333333333334\n",
      "Epoch: 83, Train loss: 0.9355948567390442, Validation loss: 0.9428179860115051, Validation acc: 0.5656\n",
      "Epoch: 84, Train loss: 0.9343839883804321, Validation loss: 0.9417773485183716, Validation acc: 0.5652666666666667\n",
      "Epoch: 85, Train loss: 0.9331890344619751, Validation loss: 0.9406633973121643, Validation acc: 0.5649333333333333\n",
      "Epoch: 86, Train loss: 0.932007372379303, Validation loss: 0.9396308064460754, Validation acc: 0.5657333333333333\n",
      "Epoch: 87, Train loss: 0.9308385252952576, Validation loss: 0.9386165738105774, Validation acc: 0.5657333333333333\n",
      "Epoch: 88, Train loss: 0.9296759963035583, Validation loss: 0.9375632405281067, Validation acc: 0.5659333333333333\n",
      "Epoch: 89, Train loss: 0.9285345673561096, Validation loss: 0.9365828037261963, Validation acc: 0.5658666666666666\n",
      "Epoch: 90, Train loss: 0.9274181127548218, Validation loss: 0.9356740117073059, Validation acc: 0.5661333333333334\n",
      "Epoch: 91, Train loss: 0.9263218641281128, Validation loss: 0.934716522693634, Validation acc: 0.566\n",
      "Epoch: 92, Train loss: 0.9252457618713379, Validation loss: 0.9337842464447021, Validation acc: 0.5666\n",
      "Epoch: 93, Train loss: 0.9241893291473389, Validation loss: 0.9328522086143494, Validation acc: 0.5664666666666667\n",
      "Epoch: 94, Train loss: 0.9231458902359009, Validation loss: 0.9320017695426941, Validation acc: 0.5667333333333333\n",
      "Epoch: 95, Train loss: 0.9221106767654419, Validation loss: 0.931085467338562, Validation acc: 0.5669333333333333\n",
      "Epoch: 96, Train loss: 0.9210851788520813, Validation loss: 0.9302436709403992, Validation acc: 0.5671333333333334\n",
      "Epoch: 97, Train loss: 0.9200798869132996, Validation loss: 0.9294046759605408, Validation acc: 0.5672666666666667\n",
      "Epoch: 98, Train loss: 0.9190794825553894, Validation loss: 0.9285963773727417, Validation acc: 0.5671333333333334\n",
      "Epoch: 99, Train loss: 0.9181013107299805, Validation loss: 0.9277381300926208, Validation acc: 0.5668666666666666\n",
      "Epoch: 100, Train loss: 0.9171266555786133, Validation loss: 0.9270368218421936, Validation acc: 0.5667333333333333\n",
      "Epoch: 101, Train loss: 0.9161615967750549, Validation loss: 0.9262696504592896, Validation acc: 0.5668\n",
      "Epoch: 102, Train loss: 0.9151953458786011, Validation loss: 0.9255350828170776, Validation acc: 0.5668\n",
      "Epoch: 103, Train loss: 0.9142711758613586, Validation loss: 0.9247804284095764, Validation acc: 0.5669333333333333\n",
      "Epoch: 104, Train loss: 0.9133325219154358, Validation loss: 0.9240744709968567, Validation acc: 0.567\n",
      "Epoch: 105, Train loss: 0.9124100208282471, Validation loss: 0.9234235286712646, Validation acc: 0.5673333333333334\n",
      "Epoch: 106, Train loss: 0.911532998085022, Validation loss: 0.9227584600448608, Validation acc: 0.5676\n",
      "Epoch: 107, Train loss: 0.9106650352478027, Validation loss: 0.9221274852752686, Validation acc: 0.5678666666666666\n",
      "Epoch: 108, Train loss: 0.9098101258277893, Validation loss: 0.9215170741081238, Validation acc: 0.5673333333333334\n",
      "Epoch: 109, Train loss: 0.9089469313621521, Validation loss: 0.9209098815917969, Validation acc: 0.5676\n",
      "Epoch: 110, Train loss: 0.9081299901008606, Validation loss: 0.9203705787658691, Validation acc: 0.5668666666666666\n",
      "Epoch: 111, Train loss: 0.9072889685630798, Validation loss: 0.9198188781738281, Validation acc: 0.567\n",
      "Epoch: 112, Train loss: 0.9064573049545288, Validation loss: 0.9192150831222534, Validation acc: 0.568\n",
      "Epoch: 113, Train loss: 0.905640184879303, Validation loss: 0.918623149394989, Validation acc: 0.5682666666666667\n",
      "Epoch: 114, Train loss: 0.9048517346382141, Validation loss: 0.9180423617362976, Validation acc: 0.5683333333333334\n",
      "Epoch: 115, Train loss: 0.9040586948394775, Validation loss: 0.917487621307373, Validation acc: 0.5687333333333333\n",
      "Epoch: 116, Train loss: 0.9033195376396179, Validation loss: 0.9169822335243225, Validation acc: 0.5686666666666667\n",
      "Epoch: 117, Train loss: 0.9025498032569885, Validation loss: 0.9164630174636841, Validation acc: 0.5689333333333333\n",
      "Epoch: 118, Train loss: 0.9017517566680908, Validation loss: 0.9158896207809448, Validation acc: 0.5688666666666666\n",
      "Epoch: 119, Train loss: 0.9010507464408875, Validation loss: 0.9154165387153625, Validation acc: 0.5688\n",
      "Epoch: 120, Train loss: 0.9003005623817444, Validation loss: 0.9149068593978882, Validation acc: 0.5685333333333333\n",
      "Epoch: 121, Train loss: 0.8995288014411926, Validation loss: 0.9144060611724854, Validation acc: 0.5682666666666667\n",
      "Epoch: 122, Train loss: 0.8988041877746582, Validation loss: 0.9138635993003845, Validation acc: 0.5682\n",
      "Epoch: 123, Train loss: 0.8981001973152161, Validation loss: 0.9133802652359009, Validation acc: 0.5674666666666667\n",
      "Epoch: 124, Train loss: 0.8974054455757141, Validation loss: 0.9128696322441101, Validation acc: 0.5674\n",
      "Epoch: 125, Train loss: 0.8967146873474121, Validation loss: 0.9124186635017395, Validation acc: 0.5678666666666666\n",
      "Epoch: 126, Train loss: 0.8960317373275757, Validation loss: 0.9119868278503418, Validation acc: 0.5671333333333334\n",
      "Epoch: 127, Train loss: 0.8953483700752258, Validation loss: 0.9115563035011292, Validation acc: 0.5673333333333334\n",
      "Epoch: 128, Train loss: 0.8946872353553772, Validation loss: 0.9111039638519287, Validation acc: 0.5673333333333334\n",
      "Epoch: 129, Train loss: 0.8940200805664062, Validation loss: 0.9106817245483398, Validation acc: 0.5671333333333334\n",
      "Epoch: 130, Train loss: 0.8934026956558228, Validation loss: 0.9102501273155212, Validation acc: 0.5674\n",
      "Epoch: 131, Train loss: 0.8927682042121887, Validation loss: 0.9098494052886963, Validation acc: 0.5667333333333333\n",
      "Epoch: 132, Train loss: 0.8920891284942627, Validation loss: 0.9094662666320801, Validation acc: 0.5664666666666667\n",
      "Epoch: 133, Train loss: 0.8914843797683716, Validation loss: 0.9090695381164551, Validation acc: 0.5663333333333334\n",
      "Epoch: 134, Train loss: 0.8908645510673523, Validation loss: 0.9086827635765076, Validation acc: 0.5660666666666667\n",
      "Epoch: 135, Train loss: 0.8902366757392883, Validation loss: 0.9082979559898376, Validation acc: 0.5661333333333334\n",
      "Epoch: 136, Train loss: 0.8896228671073914, Validation loss: 0.9079092741012573, Validation acc: 0.5658\n",
      "Epoch: 137, Train loss: 0.8890349268913269, Validation loss: 0.9074977040290833, Validation acc: 0.566\n",
      "Epoch: 138, Train loss: 0.8884559273719788, Validation loss: 0.9071170687675476, Validation acc: 0.5658666666666666\n",
      "Epoch: 139, Train loss: 0.8878328204154968, Validation loss: 0.906769871711731, Validation acc: 0.5668\n",
      "Epoch: 140, Train loss: 0.8872373104095459, Validation loss: 0.9063956141471863, Validation acc: 0.5664666666666667\n",
      "Epoch: 141, Train loss: 0.886671781539917, Validation loss: 0.9061128497123718, Validation acc: 0.5664\n",
      "Epoch: 142, Train loss: 0.886102557182312, Validation loss: 0.9057523012161255, Validation acc: 0.5657333333333333\n",
      "Epoch: 143, Train loss: 0.8855085968971252, Validation loss: 0.9054314494132996, Validation acc: 0.5654666666666667\n",
      "Epoch: 144, Train loss: 0.8849148750305176, Validation loss: 0.905098021030426, Validation acc: 0.5652666666666667\n",
      "Epoch: 145, Train loss: 0.8843619227409363, Validation loss: 0.9048028588294983, Validation acc: 0.5653333333333334\n",
      "Epoch: 146, Train loss: 0.8837960958480835, Validation loss: 0.9045209884643555, Validation acc: 0.5650666666666667\n",
      "Epoch: 147, Train loss: 0.8832369446754456, Validation loss: 0.9041942954063416, Validation acc: 0.5651333333333334\n",
      "Epoch: 148, Train loss: 0.8826599717140198, Validation loss: 0.9039100408554077, Validation acc: 0.565\n",
      "Epoch: 149, Train loss: 0.8821184635162354, Validation loss: 0.9036461710929871, Validation acc: 0.5652666666666667\n",
      "Epoch: 150, Train loss: 0.8815601468086243, Validation loss: 0.903376042842865, Validation acc: 0.5655333333333333\n",
      "Epoch: 151, Train loss: 0.8810275197029114, Validation loss: 0.903102695941925, Validation acc: 0.5656666666666667\n",
      "Epoch: 152, Train loss: 0.8804629445075989, Validation loss: 0.9028607606887817, Validation acc: 0.5653333333333334\n",
      "Epoch: 153, Train loss: 0.8799031376838684, Validation loss: 0.902575671672821, Validation acc: 0.5653333333333334\n",
      "Epoch: 154, Train loss: 0.8793598413467407, Validation loss: 0.902295708656311, Validation acc: 0.5654\n",
      "Epoch: 155, Train loss: 0.8788273334503174, Validation loss: 0.9020074605941772, Validation acc: 0.5650666666666667\n",
      "Epoch: 156, Train loss: 0.8782858848571777, Validation loss: 0.9017726182937622, Validation acc: 0.5648666666666666\n",
      "Epoch: 157, Train loss: 0.8777692317962646, Validation loss: 0.9015715718269348, Validation acc: 0.5648666666666666\n",
      "Epoch: 158, Train loss: 0.8772515654563904, Validation loss: 0.9013679027557373, Validation acc: 0.5651333333333334\n",
      "Epoch: 159, Train loss: 0.8767572045326233, Validation loss: 0.9011522531509399, Validation acc: 0.5642666666666667\n",
      "Epoch: 160, Train loss: 0.8762495517730713, Validation loss: 0.9010239839553833, Validation acc: 0.5638666666666666\n",
      "Epoch: 161, Train loss: 0.8757645487785339, Validation loss: 0.9008078575134277, Validation acc: 0.5637333333333333\n",
      "Epoch: 162, Train loss: 0.875260591506958, Validation loss: 0.9006483554840088, Validation acc: 0.5638\n",
      "Epoch: 163, Train loss: 0.8747751116752625, Validation loss: 0.9004483222961426, Validation acc: 0.5638\n",
      "Epoch: 164, Train loss: 0.8742939233779907, Validation loss: 0.9002798199653625, Validation acc: 0.5637333333333333\n",
      "Epoch: 165, Train loss: 0.873831033706665, Validation loss: 0.9001051187515259, Validation acc: 0.5638\n",
      "Epoch: 166, Train loss: 0.8733626008033752, Validation loss: 0.900007426738739, Validation acc: 0.5639333333333333\n",
      "Epoch: 167, Train loss: 0.8729152679443359, Validation loss: 0.899829089641571, Validation acc: 0.5637333333333333\n",
      "Epoch: 168, Train loss: 0.8724522590637207, Validation loss: 0.8997156620025635, Validation acc: 0.5644\n",
      "Epoch: 169, Train loss: 0.8720288276672363, Validation loss: 0.8995610475540161, Validation acc: 0.5649333333333333\n",
      "Epoch: 170, Train loss: 0.8715639114379883, Validation loss: 0.8994967341423035, Validation acc: 0.5649333333333333\n",
      "Epoch: 171, Train loss: 0.8711426854133606, Validation loss: 0.899240255355835, Validation acc: 0.5646\n",
      "Epoch: 172, Train loss: 0.870671272277832, Validation loss: 0.8993098139762878, Validation acc: 0.5648\n",
      "Epoch: 173, Train loss: 0.8702811002731323, Validation loss: 0.8989759087562561, Validation acc: 0.565\n",
      "Epoch: 174, Train loss: 0.8698018193244934, Validation loss: 0.8991156220436096, Validation acc: 0.5639333333333333\n",
      "Epoch: 175, Train loss: 0.8694359660148621, Validation loss: 0.8986937403678894, Validation acc: 0.5646666666666667\n",
      "Epoch: 176, Train loss: 0.8689579367637634, Validation loss: 0.8988871574401855, Validation acc: 0.5647333333333333\n",
      "Epoch: 177, Train loss: 0.8685940504074097, Validation loss: 0.8984315991401672, Validation acc: 0.5646\n",
      "Epoch: 178, Train loss: 0.8681032061576843, Validation loss: 0.8986621499061584, Validation acc: 0.5645333333333333\n",
      "Epoch: 179, Train loss: 0.8677618503570557, Validation loss: 0.8982124924659729, Validation acc: 0.5646\n",
      "Epoch: 180, Train loss: 0.8672590255737305, Validation loss: 0.8984172344207764, Validation acc: 0.5651333333333334\n",
      "Epoch: 181, Train loss: 0.866919755935669, Validation loss: 0.8980504274368286, Validation acc: 0.5654666666666667\n",
      "Epoch: 182, Train loss: 0.8664321899414062, Validation loss: 0.8981672525405884, Validation acc: 0.5654\n",
      "Epoch: 183, Train loss: 0.8660830855369568, Validation loss: 0.8978559970855713, Validation acc: 0.5653333333333334\n",
      "Epoch: 184, Train loss: 0.8656008243560791, Validation loss: 0.8979764580726624, Validation acc: 0.5657333333333333\n",
      "Epoch: 185, Train loss: 0.8652451634407043, Validation loss: 0.8976644277572632, Validation acc: 0.5656\n",
      "Epoch: 186, Train loss: 0.8647725582122803, Validation loss: 0.8978321552276611, Validation acc: 0.5657333333333333\n",
      "Epoch: 187, Train loss: 0.8644315600395203, Validation loss: 0.8975340723991394, Validation acc: 0.5656\n",
      "Epoch: 188, Train loss: 0.8639521598815918, Validation loss: 0.897582471370697, Validation acc: 0.5656\n",
      "Epoch: 189, Train loss: 0.8636419773101807, Validation loss: 0.8972848057746887, Validation acc: 0.5656\n",
      "Epoch: 190, Train loss: 0.8631044030189514, Validation loss: 0.8973960876464844, Validation acc: 0.5662\n",
      "Epoch: 191, Train loss: 0.8628019690513611, Validation loss: 0.8971367478370667, Validation acc: 0.5654\n",
      "Epoch: 192, Train loss: 0.8623483180999756, Validation loss: 0.8972339034080505, Validation acc: 0.5656\n",
      "Epoch: 193, Train loss: 0.8620234131813049, Validation loss: 0.8969477415084839, Validation acc: 0.5656\n",
      "Epoch: 194, Train loss: 0.8615477681159973, Validation loss: 0.8970824480056763, Validation acc: 0.5653333333333334\n",
      "Epoch: 195, Train loss: 0.8612276315689087, Validation loss: 0.8968415260314941, Validation acc: 0.5658\n",
      "Epoch: 196, Train loss: 0.8607656359672546, Validation loss: 0.8969992995262146, Validation acc: 0.5648\n",
      "Epoch: 197, Train loss: 0.8604525327682495, Validation loss: 0.8967658281326294, Validation acc: 0.5654\n",
      "Epoch: 198, Train loss: 0.8600075840950012, Validation loss: 0.8969079852104187, Validation acc: 0.5649333333333333\n",
      "Epoch: 199, Train loss: 0.8597233891487122, Validation loss: 0.896841824054718, Validation acc: 0.5652\n"
     ]
    }
   ],
   "source": [
    "train_loss, valid_loss = [], []\n",
    "for i, epoch in enumerate(range(n_epoch)):\n",
    "\n",
    "    model.train()\n",
    "    for data_i, target_i, len_i in train_loader:\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output = model(data_i, len_i)\n",
    "     #   print(output.shape, target_i.view(-1,4).shape)\n",
    "        loss = loss_function(output.permute(0,2,1), target_i.view(output.shape[0], -1))  \n",
    "#         loss = calc_loss(output, target_i.view(-1,4)) \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss.append(loss.item())\n",
    "    #auc_train = calc_auc(model, train_loader)\n",
    "\n",
    "\n",
    "    acc = 0\n",
    "    model.eval()\n",
    "    for data_i, target_i, len_i in test_loader:\n",
    "        output = model(data_i, len_i)\n",
    "        loss2 = loss_function(output.permute(0,2,1), target_i.view(output.shape[0], -1)) \n",
    "        #loss2 = calc_loss(output, target_i) \n",
    "        valid_loss.append(loss2.item())\n",
    "        _, preds_tensor = torch.max(output.permute(0,2,1), 1)\n",
    "        preds = np.squeeze(preds_tensor.numpy())\n",
    "        acc +=np.average(target_i.numpy().reshape(-1,MAX_SEQ_LENGTH) == preds) # Here 4\n",
    "    \n",
    "   # auc_test = calc_auc(model, test_loader)\n",
    "    acc = acc/len(test_loader)\n",
    "    print(\"Epoch: {}, Train loss: {}, Validation loss: {}, Validation acc: {}\".format(i,train_loss[-1], valid_loss[-1], acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2, 2, 2, 2, 2],\n",
       "        [2, 2, 2, 2, 2],\n",
       "        [1, 1, 2, 2, 1],\n",
       "        ...,\n",
       "        [2, 2, 2, 2, 2],\n",
       "        [2, 1, 1, 2, 2],\n",
       "        [2, 1, 1, 1, 1]])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = F.softmax(output, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader2 = DataLoader(x_test, batch_size=len(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "for data_i, target_i, len_i in test_loader2:\n",
    "    out1 = model(data_i, len_i)\n",
    "    tar1 = target_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = F.softmax(out1, dim=2).detach().squeeze().numpy()\n",
    "tar = target_i.detach().squeeze().numpy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_pred = []\n",
    "filtered_truth = []\n",
    "for i, pred_i in enumerate(pred):\n",
    "    filtered_pred += list(pred_i[:len_i[i]])\n",
    "\n",
    "for i, tar_i in enumerate(tar):\n",
    "    filtered_truth += list(tar_i[:len_i[i]])  \n",
    "filtered_pred = np.array(filtered_pred)\n",
    "filtered_truth = np.array(filtered_truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12602, 12602)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(filtered_pred), len(filtered_truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12602, 4)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12602,)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_truth.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_col(sorted_df, ticker, col):      \n",
    "    ticker_data = sorted_df.loc[sorted_df['ticker'] == ticker, :]    \n",
    "    df_col = ticker_data.loc[:, col]    \n",
    "    return list(df_col.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "pct_shifted = []\n",
    "\n",
    "for ticker in test_tickers:\n",
    "    pct_shifted = pct_shifted + extract_col(df_test_all, ticker, 'pct_change_shifted')\n",
    "    \n",
    "pct_shifted = np.array(pct_shifted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12602"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pct_shifted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "market_cap, net_margin, date_key = [], [], []\n",
    "\n",
    "for ticker in test_tickers:\n",
    "    market_cap = market_cap + extract_col(df_test_all, ticker, 'marketcap')\n",
    "    net_margin = net_margin + extract_col(df_test_all, ticker, 'netmargin')\n",
    "    date_key = date_key + extract_col(df_test_all, ticker, 'datekey')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "market_cap = np.array(market_cap)\n",
    "net_margin = np.array(net_margin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_key = np.array(date_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_recent = date_key>np.datetime64('2018-01-01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mask_recent "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2857482939215997"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.average(mask_recent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/snexus/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: RuntimeWarning: invalid value encountered in greater\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "mask_risky = (market_cap>1e6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.03020526, 0.42202592, 0.49487323, 0.0528956 ],\n",
       "       [0.02055642, 0.4618836 , 0.4750381 , 0.04252192],\n",
       "       [0.00774341, 0.41148365, 0.55700547, 0.02376739],\n",
       "       ...,\n",
       "       [0.24803805, 0.42570543, 0.23502232, 0.09123426],\n",
       "       [0.27804086, 0.40122643, 0.21338484, 0.10734784],\n",
       "       [0.31298637, 0.36909035, 0.23697874, 0.08094449]], dtype=float32)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_pred = np.argsort(filtered_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 3, 1, 2],\n",
       "       [0, 3, 1, 2],\n",
       "       [0, 3, 1, 2],\n",
       "       ...,\n",
       "       [3, 2, 0, 1],\n",
       "       [3, 2, 0, 1],\n",
       "       [3, 2, 0, 1]])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "select_shares1 = ((sorted_pred[:,-1]==2) | (sorted_pred[:,-1]==3)) & ((filtered_pred[:,-1])>0.17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "select_shares2 = ((sorted_pred[:,-1]==3) & (sorted_pred[:,-2]==2)) & (filtered_pred[:,0]<0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False, ..., False, False, False])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "select_shares2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.03020526, 0.42202592, 0.49487323, 0.0528956 ],\n",
       "       [0.02055642, 0.4618836 , 0.4750381 , 0.04252192],\n",
       "       [0.00774341, 0.41148365, 0.55700547, 0.02376739],\n",
       "       ...,\n",
       "       [0.24803805, 0.42570543, 0.23502232, 0.09123426],\n",
       "       [0.27804086, 0.40122643, 0.21338484, 0.10734784],\n",
       "       [0.31298637, 0.36909035, 0.23697874, 0.08094449]], dtype=float32)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "select_shares3 =(filtered_pred[:,2]/filtered_pred[:,1] > 3) & mask_risky"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "select_shares4 = ((filtered_pred[:,3]+filtered_pred[:,2])>0.8)  &mask_risky"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "shares1 = pct_shifted[select_shares1]\n",
    "shares2 = pct_shifted[select_shares2]\n",
    "shares3 = pct_shifted[select_shares3]\n",
    "shares4 = pct_shifted[select_shares4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.19095363e-04, 2.40206763e-01, 7.56365359e-01, 3.30871739e-03],\n",
       "       [7.23034842e-04, 2.25128070e-01, 7.61616588e-01, 1.25323376e-02],\n",
       "       [6.73954724e-04, 1.94854707e-01, 7.90443003e-01, 1.40282838e-02],\n",
       "       [4.79672308e-04, 1.65143818e-01, 8.24505746e-01, 9.87078436e-03],\n",
       "       [1.18252169e-03, 2.14369729e-01, 7.75791943e-01, 8.65578093e-03],\n",
       "       [3.15184792e-04, 1.52856231e-01, 8.41023266e-01, 5.80532942e-03],\n",
       "       [2.03032047e-04, 1.28667802e-01, 8.65833223e-01, 5.29589504e-03],\n",
       "       [1.93577303e-04, 1.19213812e-01, 8.74929488e-01, 5.66302845e-03],\n",
       "       [2.21937872e-03, 2.38697320e-01, 7.48078108e-01, 1.10052517e-02],\n",
       "       [2.60632252e-03, 2.33888924e-01, 7.52127528e-01, 1.13772312e-02],\n",
       "       [2.15380918e-03, 2.03901738e-01, 7.73866236e-01, 2.00782083e-02],\n",
       "       [1.72653364e-03, 1.65464967e-01, 8.06914389e-01, 2.58939862e-02],\n",
       "       [1.48369919e-03, 1.45108595e-01, 8.25488865e-01, 2.79188566e-02],\n",
       "       [8.37211777e-03, 2.38504380e-01, 7.33842969e-01, 1.92805212e-02],\n",
       "       [1.43170943e-02, 1.93242997e-01, 7.72887230e-01, 1.95526741e-02],\n",
       "       [1.58621918e-03, 2.41903752e-01, 7.55422652e-01, 1.08736765e-03],\n",
       "       [9.48976158e-05, 2.39465699e-01, 7.58711994e-01, 1.72740675e-03],\n",
       "       [6.03351436e-05, 2.23407105e-01, 7.74907112e-01, 1.62540609e-03],\n",
       "       [4.70956147e-05, 2.11564988e-01, 7.86747038e-01, 1.64077885e-03],\n",
       "       [3.72118829e-03, 2.28698432e-01, 7.60318577e-01, 7.26174889e-03],\n",
       "       [4.41824412e-03, 1.72555819e-01, 8.16563487e-01, 6.46242592e-03],\n",
       "       [5.57743013e-03, 1.39002860e-01, 8.50557208e-01, 4.86249244e-03],\n",
       "       [6.71773637e-03, 1.22693561e-01, 8.66618872e-01, 3.96982394e-03],\n",
       "       [2.24315096e-03, 2.39724711e-01, 7.54339337e-01, 3.69283627e-03],\n",
       "       [2.36017676e-03, 2.06918761e-01, 7.88717210e-01, 2.00378033e-03],\n",
       "       [2.97885761e-03, 2.02634811e-01, 7.93141067e-01, 1.24530669e-03],\n",
       "       [4.95383691e-04, 2.46495739e-01, 7.51037538e-01, 1.97137892e-03],\n",
       "       [4.18698211e-04, 2.20530480e-01, 7.77943909e-01, 1.10692449e-03],\n",
       "       [6.12955820e-03, 2.03477442e-01, 7.70307958e-01, 2.00850647e-02],\n",
       "       [1.90650895e-02, 2.05341041e-01, 7.23414958e-01, 5.21788448e-02],\n",
       "       [3.20490263e-02, 2.06606820e-01, 6.89097345e-01, 7.22467825e-02],\n",
       "       [8.53614323e-03, 2.44637504e-01, 7.35331237e-01, 1.14950743e-02],\n",
       "       [9.08733997e-03, 2.10907057e-01, 7.73010850e-01, 6.99475221e-03],\n",
       "       [2.10816250e-03, 2.16726184e-01, 7.79009581e-01, 2.15609698e-03],\n",
       "       [2.97628995e-03, 1.99104354e-01, 7.95342803e-01, 2.57654814e-03],\n",
       "       [1.39131583e-03, 2.42805138e-01, 7.54228532e-01, 1.57507067e-03],\n",
       "       [1.39632949e-03, 2.31683865e-01, 7.65542626e-01, 1.37723435e-03],\n",
       "       [1.29961164e-03, 2.34241694e-01, 7.63236582e-01, 1.22212444e-03],\n",
       "       [9.13352296e-02, 2.01024905e-01, 6.70683146e-01, 3.69568169e-02],\n",
       "       [6.42698584e-03, 2.15879172e-01, 7.53615499e-01, 2.40782704e-02],\n",
       "       [6.70434395e-03, 1.94249570e-01, 7.76466608e-01, 2.25795135e-02],\n",
       "       [5.98273985e-03, 1.79781914e-01, 7.99899518e-01, 1.43357944e-02],\n",
       "       [1.97141133e-02, 2.41548255e-01, 7.34325469e-01, 4.41220496e-03],\n",
       "       [1.54626817e-02, 1.92346126e-01, 7.82000363e-01, 1.01908455e-02],\n",
       "       [1.05620944e-03, 1.71778262e-01, 8.25626612e-01, 1.53896969e-03],\n",
       "       [5.98462066e-04, 1.31162971e-01, 8.67088318e-01, 1.15026790e-03],\n",
       "       [7.94200227e-04, 1.11890338e-01, 8.86141956e-01, 1.17354421e-03],\n",
       "       [8.93255637e-04, 9.88687351e-02, 8.99257243e-01, 9.80737968e-04],\n",
       "       [1.65261358e-01, 1.39723122e-01, 6.43921793e-01, 5.10937274e-02],\n",
       "       [2.22755626e-01, 6.69878423e-02, 6.35493875e-01, 7.47627020e-02],\n",
       "       [2.28584751e-01, 5.86034507e-02, 6.33110464e-01, 7.97013342e-02],\n",
       "       [1.59000643e-02, 2.22104251e-01, 7.58109808e-01, 3.88592714e-03],\n",
       "       [6.58908021e-03, 1.64845422e-01, 8.26362073e-01, 2.20345962e-03],\n",
       "       [6.41712593e-03, 1.32943973e-01, 8.58521342e-01, 2.11752625e-03],\n",
       "       [1.99295860e-03, 1.58884600e-01, 8.37821126e-01, 1.30132702e-03],\n",
       "       [1.02563925e-01, 2.05773443e-01, 6.72197580e-01, 1.94650237e-02],\n",
       "       [5.64039834e-02, 1.09090999e-01, 8.11621904e-01, 2.28831004e-02],\n",
       "       [5.35462320e-01, 7.45362863e-02, 3.82667005e-01, 7.33441021e-03],\n",
       "       [8.25285971e-01, 2.74519920e-02, 1.43260643e-01, 4.00138972e-03],\n",
       "       [1.02274260e-03, 2.35001430e-01, 7.63387740e-01, 5.88186085e-04],\n",
       "       [2.46957392e-02, 2.13329464e-01, 7.15534270e-01, 4.64405641e-02],\n",
       "       [1.37072837e-03, 2.23408222e-01, 7.73032665e-01, 2.18839431e-03],\n",
       "       [8.60317785e-04, 1.89599305e-01, 8.08155656e-01, 1.38466817e-03],\n",
       "       [8.69892305e-04, 1.73215181e-01, 8.24841440e-01, 1.07348943e-03],\n",
       "       [8.28485296e-04, 1.80773363e-01, 8.17425311e-01, 9.72913462e-04],\n",
       "       [7.37640709e-02, 2.00151131e-01, 6.78336322e-01, 4.77484986e-02],\n",
       "       [3.69652137e-02, 2.19427213e-01, 7.06708610e-01, 3.68989632e-02],\n",
       "       [4.72622782e-01, 8.07628185e-02, 3.07360381e-01, 1.39254034e-01],\n",
       "       [2.73004919e-01, 9.95855555e-02, 4.00907904e-01, 2.26501659e-01],\n",
       "       [5.71079552e-02, 2.29197443e-01, 7.04271436e-01, 9.42322705e-03],\n",
       "       [9.61581524e-03, 2.21499100e-01, 7.53984272e-01, 1.49008175e-02],\n",
       "       [6.10628165e-02, 2.06756160e-01, 6.43886566e-01, 8.82945061e-02],\n",
       "       [8.67077231e-01, 1.51861683e-02, 5.95514439e-02, 5.81851415e-02],\n",
       "       [3.65635306e-01, 7.05488175e-02, 5.53169250e-01, 1.06465966e-02],\n",
       "       [4.21576768e-01, 3.50345634e-02, 5.37408292e-01, 5.98032121e-03],\n",
       "       [4.69055712e-01, 3.31947245e-02, 4.91642386e-01, 6.10710960e-03],\n",
       "       [4.33959901e-01, 3.90335247e-02, 5.20029008e-01, 6.97750319e-03],\n",
       "       [2.07120657e-01, 7.07903430e-02, 7.10904896e-01, 1.11841625e-02],\n",
       "       [3.29808536e-04, 2.31934935e-01, 7.64804125e-01, 2.93108355e-03],\n",
       "       [2.79407133e-04, 1.99806169e-01, 7.97160625e-01, 2.75381398e-03],\n",
       "       [2.93808116e-04, 1.78048939e-01, 8.19163978e-01, 2.49325810e-03],\n",
       "       [1.44392703e-04, 2.36968547e-01, 7.61800826e-01, 1.08618627e-03],\n",
       "       [1.11419722e-04, 2.08543256e-01, 7.90364563e-01, 9.80765675e-04],\n",
       "       [1.02301645e-04, 1.90934777e-01, 8.07907820e-01, 1.05510349e-03],\n",
       "       [1.68900993e-02, 2.33617008e-01, 7.34528005e-01, 1.49648767e-02],\n",
       "       [8.21904838e-03, 2.16750786e-01, 7.58548200e-01, 1.64819546e-02],\n",
       "       [1.01409048e-01, 1.58760831e-01, 6.99779749e-01, 4.00504135e-02],\n",
       "       [3.73907940e-04, 2.08854824e-01, 7.87425518e-01, 3.34574096e-03],\n",
       "       [3.93542898e-04, 2.08887711e-01, 7.88070142e-01, 2.64856266e-03],\n",
       "       [2.44685769e-04, 1.44467428e-01, 8.51052999e-01, 4.23488300e-03],\n",
       "       [2.18223868e-04, 1.22095115e-01, 8.73152375e-01, 4.53427853e-03],\n",
       "       [8.20593834e-02, 1.97121203e-01, 6.99383140e-01, 2.14362871e-02],\n",
       "       [7.35442787e-02, 2.03929141e-01, 7.07982719e-01, 1.45439189e-02],\n",
       "       [1.48357958e-01, 1.98159948e-01, 6.35141611e-01, 1.83404721e-02],\n",
       "       [1.84708297e-01, 1.94968343e-01, 5.97568989e-01, 2.27543991e-02],\n",
       "       [1.19861193e-01, 1.87294424e-01, 6.24084771e-01, 6.87595978e-02],\n",
       "       [2.51500926e-04, 2.46484995e-01, 7.52515912e-01, 7.47660466e-04],\n",
       "       [5.55709824e-02, 1.19048730e-01, 3.99955094e-01, 4.25425202e-01],\n",
       "       [3.04520037e-02, 1.20750688e-01, 5.21830618e-01, 3.26966614e-01],\n",
       "       [5.07683337e-01, 5.49613610e-02, 4.05540526e-01, 3.18146721e-02],\n",
       "       [6.64657354e-03, 1.92100853e-01, 7.98521996e-01, 2.73056468e-03],\n",
       "       [4.80975397e-03, 1.41933560e-01, 8.51402462e-01, 1.85424217e-03],\n",
       "       [5.04721748e-03, 1.14160359e-01, 8.79158914e-01, 1.63356273e-03],\n",
       "       [5.34905540e-03, 1.00480244e-01, 8.92621696e-01, 1.54902390e-03],\n",
       "       [1.43571747e-02, 1.71141207e-01, 7.90463328e-01, 2.40382757e-02],\n",
       "       [2.92262994e-03, 2.11604431e-01, 7.78380096e-01, 7.09281582e-03],\n",
       "       [9.53652710e-03, 2.26070911e-01, 7.52862990e-01, 1.15295397e-02],\n",
       "       [9.60305426e-03, 2.37049475e-01, 7.45032072e-01, 8.31533689e-03],\n",
       "       [1.44426888e-02, 2.35465765e-01, 7.27856219e-01, 2.22353004e-02],\n",
       "       [2.98459083e-01, 1.41311035e-01, 5.50567091e-01, 9.66275763e-03],\n",
       "       [2.65192967e-02, 2.11675599e-01, 7.19423592e-01, 4.23815362e-02],\n",
       "       [7.67994998e-03, 2.34815449e-01, 7.31827617e-01, 2.56769620e-02],\n",
       "       [2.57101539e-03, 2.10979328e-01, 7.66551375e-01, 1.98982507e-02],\n",
       "       [1.25573967e-02, 1.91765830e-01, 7.43763506e-01, 5.19133322e-02],\n",
       "       [1.38291372e-02, 2.02393815e-01, 6.17567003e-01, 1.66209966e-01],\n",
       "       [7.09443493e-03, 2.07339630e-01, 6.44162118e-01, 1.41403764e-01],\n",
       "       [5.25858952e-03, 2.15766028e-01, 6.54717326e-01, 1.24257997e-01],\n",
       "       [4.02564108e-01, 9.66611728e-02, 4.57046181e-01, 4.37286794e-02],\n",
       "       [3.98348868e-01, 9.31639597e-02, 4.65873420e-01, 4.26137894e-02],\n",
       "       [1.82749427e-04, 2.26306602e-01, 7.72469401e-01, 1.04126940e-03],\n",
       "       [1.00515259e-04, 2.20030203e-01, 7.79087663e-01, 7.81586161e-04],\n",
       "       [8.43214148e-05, 1.97517976e-01, 8.01750481e-01, 6.47286535e-04],\n",
       "       [7.17977091e-05, 1.67661354e-01, 8.31744134e-01, 5.22773247e-04],\n",
       "       [1.50399515e-02, 2.36307532e-01, 7.26107776e-01, 2.25447100e-02],\n",
       "       [3.33651975e-02, 2.14741826e-01, 6.73222125e-01, 7.86708295e-02],\n",
       "       [1.59435179e-02, 2.21333832e-01, 7.47663677e-01, 1.50589515e-02],\n",
       "       [9.06732917e-01, 1.74494907e-02, 7.10856616e-02, 4.73191962e-03],\n",
       "       [7.70881891e-01, 4.51468974e-02, 1.72830999e-01, 1.11402450e-02],\n",
       "       [7.79165149e-01, 2.59814784e-02, 1.85530826e-01, 9.32261534e-03],\n",
       "       [7.31647491e-01, 2.14259736e-02, 2.35390753e-01, 1.15357377e-02],\n",
       "       [9.56408679e-04, 2.35565588e-01, 7.61789024e-01, 1.68903929e-03],\n",
       "       [9.52812261e-04, 2.15653583e-01, 7.81961679e-01, 1.43193349e-03],\n",
       "       [1.28852925e-03, 2.29160249e-01, 7.68131137e-01, 1.42004143e-03],\n",
       "       [1.65810008e-02, 2.15879187e-01, 7.43656576e-01, 2.38832105e-02],\n",
       "       [2.55015418e-02, 2.05979794e-01, 7.43016720e-01, 2.55019888e-02],\n",
       "       [1.50026968e-02, 1.94708824e-01, 7.64383078e-01, 2.59054452e-02],\n",
       "       [1.73643436e-02, 1.64308012e-01, 7.90359080e-01, 2.79685594e-02],\n",
       "       [5.43138497e-02, 2.04740837e-01, 6.68830097e-01, 7.21152574e-02],\n",
       "       [4.33950499e-02, 1.85283259e-01, 6.85841441e-01, 8.54802579e-02],\n",
       "       [3.80764976e-02, 1.84555471e-01, 6.96061194e-01, 8.13068375e-02]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_pred[select_shares3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9, 115, 140, 36, 12602)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(shares2), len(shares1), len(shares3), len(shares4), len(pct_shifted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09433858467995113"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.average(shares2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01329217338511605"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.average(pct_shifted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "sell_threshold = -0.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "shares3[shares3<sell_threshold] = sell_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "shares1[shares1<sell_threshold] = sell_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.026482587606040837"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.average(shares1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05992798820539029"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.average(shares3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "shares4[shares4<sell_threshold] = sell_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07442643375648093"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.average(shares4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.43478261e-01,  6.06463878e-01,  1.88000000e-01, -1.50000000e-01,\n",
       "        2.17430368e-01, -1.12177122e-01, -6.53384949e-02,  8.09813983e-03,\n",
       "       -5.51181102e-02,  2.22297070e-01,  3.74531835e-03,  1.24122037e-01,\n",
       "       -5.36952065e-03,  1.21711818e-02,  7.16220283e-02,  2.49605885e-02,\n",
       "        1.20481928e-02, -1.34746180e-01,  1.50603782e-01,  2.89108911e-02,\n",
       "       -2.96381832e-02,  2.12014134e-02,  1.24567474e-02,  1.17132867e-01,\n",
       "       -1.50000000e-01, -1.50000000e-01, -5.93505039e-02, -4.88095238e-02,\n",
       "        8.07748538e-02, -1.50000000e-01, -7.54716981e-02, -5.52220888e-02,\n",
       "        5.04023719e-02,  7.75193798e-02, -5.99520384e-02,  5.21100917e-01,\n",
       "        5.76598311e-01, -1.50000000e-01,  2.42712671e-01,  1.02262163e-01,\n",
       "        2.54990160e-01,  1.06503512e-02, -1.97044335e-02,  8.54271357e-02,\n",
       "       -1.50000000e-01, -1.02083333e-01, -1.50000000e-01,  2.63157895e-01,\n",
       "       -1.50000000e-01, -3.01659125e-02, -1.02643857e-01,  1.36033229e-01,\n",
       "        2.12065814e-01,  1.04826546e-01, -3.54772843e-02,  1.42032333e-01,\n",
       "       -1.17290192e-01,  6.87285223e-03, -1.50000000e-01,  1.04234528e-01,\n",
       "        6.08525870e-02,  9.53516091e-03,  9.58083832e-02,  2.74702172e-02,\n",
       "       -6.52599521e-04,  4.70370370e-02, -1.50000000e-01, -1.50000000e-01,\n",
       "        2.86792453e-01,  1.66177908e-02, -1.50000000e-01, -1.50000000e-01,\n",
       "        2.12635870e-01,  1.79831933e-01, -1.27250900e-01,  1.00412655e-01,\n",
       "       -6.66666667e-02, -1.50000000e-01,  3.12167057e-02,  1.44019528e-01,\n",
       "        5.03442341e-02, -3.80991397e-02,  1.15794349e-02,  2.24785761e-01,\n",
       "        9.63401507e-02, -1.50000000e-01,  6.92090395e-02, -1.50000000e-01,\n",
       "       -1.40414696e-01, -1.50000000e-01, -1.50000000e-01,  4.20475320e-02,\n",
       "       -1.25375243e-02, -3.21888412e-02,  1.98447894e-01,  1.77304965e-02,\n",
       "        2.47706422e-01,  2.00226815e-01,  9.67979003e-02, -6.03043936e-03,\n",
       "       -1.50000000e-01,  3.17460317e-03, -1.50000000e-01, -1.50000000e-01,\n",
       "       -1.50000000e-01,  1.95151515e-01, -1.50000000e-01,  5.73355818e-02,\n",
       "       -1.50000000e-01, -4.61538462e-02,  1.20078740e-01,  4.50261780e-01,\n",
       "        1.87651822e+00, -1.50000000e-01, -1.50000000e-01,  2.91569087e-01,\n",
       "       -1.50000000e-01, -7.38619234e-03, -3.48519362e-02, -1.01491863e-01,\n",
       "        3.50713842e-01,  1.43229167e-01, -1.77838577e-02,  3.78830084e-01,\n",
       "       -1.50000000e-01, -7.16981132e-02,  2.57776250e-02, -6.08090360e-02,\n",
       "       -1.50000000e-01,  4.97587455e-02, -1.50000000e-01,  4.51895044e-02,\n",
       "        1.25239006e-01,  4.23109601e-01, -6.48527767e-02, -2.08333333e-02,\n",
       "        2.04545455e-01, -9.66183575e-02,  4.82456140e-02,  1.24191708e-01,\n",
       "       -1.50000000e-01,  4.84098940e-02, -9.48275862e-02, -6.80272109e-03,\n",
       "       -1.50000000e-01, -1.50000000e-01,  2.53192671e-01,  5.68836406e-03,\n",
       "       -1.50000000e-01, -1.22525919e-02, -4.86641221e-02,  2.33701103e-01,\n",
       "       -1.50000000e-01,  9.81924768e-02, -1.50000000e-01,  1.20603015e-01,\n",
       "        1.07236842e-01,  2.06773619e-01,  1.80699163e-01,  2.46173071e-01,\n",
       "        1.09698330e-02, -8.95191122e-02, -9.83206934e-02, -1.50000000e-01,\n",
       "        6.71045117e-03,  7.31811091e-02,  4.68451243e-02,  3.24200913e-01,\n",
       "       -3.74812594e-02, -1.22994652e-01,  2.19428571e-01, -2.99906279e-02,\n",
       "        1.65492958e-01, -1.50000000e-01,  1.53658537e-01, -1.50000000e-01,\n",
       "       -1.50000000e-01,  2.52016129e-01,  1.29895366e-01, -2.20928694e-02,\n",
       "        2.07061640e-01, -1.50000000e-01, -1.50000000e-01,  4.47227191e-02,\n",
       "       -2.14592275e-02, -1.19013062e-01, -1.50000000e-01, -1.43564356e-01,\n",
       "        8.46153846e-02, -5.31914894e-02,  4.81586402e-02, -2.16216216e-02,\n",
       "       -7.52712999e-02, -5.90909091e-02, -1.32505176e-01, -1.50000000e-01,\n",
       "       -6.61070304e-02, -1.50000000e-01,  1.09375000e-01,  4.61263409e-01,\n",
       "        2.81250000e-01, -7.33391938e-02, -6.66666667e-02,  2.92397661e-02,\n",
       "        8.97294920e-02,  4.71854305e-02, -1.25955204e-01,  3.30766113e-01,\n",
       "       -3.10116086e-02,  1.31560653e-01, -6.92673936e-02,  5.35066505e-02,\n",
       "        2.66840052e-01, -1.23177992e-01, -1.41932390e-01, -4.66010089e-02,\n",
       "        5.42056075e-02,  5.67375887e-02, -1.50000000e-01, -1.50000000e-01,\n",
       "       -1.50000000e-01, -4.06587751e-02,  8.70420457e-02, -4.32385374e-02,\n",
       "        1.88309415e-01, -1.07249255e-02,  7.79753762e-02,  6.53594771e-04,\n",
       "       -1.50000000e-01,  1.01932550e-01,  9.78335626e-02, -1.01801096e-02,\n",
       "        1.31803797e-01, -8.59779114e-02,  2.55778120e-01,  2.60736196e-02,\n",
       "       -6.10328638e-02, -3.78006873e-02, -8.57142857e-02,  3.53356890e-02,\n",
       "        1.25938567e-01,  1.24280085e-01,  5.04179024e-02,  1.64383562e-01,\n",
       "       -3.78684365e-02,  1.83607223e-01,  4.01606426e-03, -6.93756194e-03,\n",
       "       -1.50000000e-01,  8.94175554e-02, -1.50000000e-01,  8.27532869e-02,\n",
       "        1.28571429e-02,  1.50060024e-01,  5.95959596e-03,  1.50694608e-02,\n",
       "        3.16176471e-02,  6.73556664e-02, -3.90651085e-02, -1.03192519e-02,\n",
       "       -1.00924635e-02, -1.02990033e-02,  3.35683115e-03,  9.56841753e-02,\n",
       "       -1.02680013e-01,  1.97193235e-01,  4.94740006e-01, -6.37254902e-02,\n",
       "        7.06806283e-02,  1.11836735e-01, -2.93685756e-02, -9.82624326e-02,\n",
       "        2.88805771e-01,  8.00165837e-02,  1.90307329e-01])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shares4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.average(pct_shifted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask=select_shares3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(filtered_pred[mask]), len(pct_shifted[mask])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax, fig = plt.subplots(figsize=(16,12))\n",
    "plt.scatter(filtered_pred[mask, -1]+filtered_pred[mask, -2],  shares3, alpha=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(shares3, bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mask = (market_cap>1000000.0) & (net_margin > -0.5) & (filtered_pred>0.3)\n",
    "mask = (filtered_pred>0.12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(filtered_pred[mask])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.average(pct_shifted[mask])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax, fig = plt.subplots(figsize=(16,12))\n",
    "plt.scatter(filtered_pred[mask], pct_shifted[mask], alpha=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = out1.detach().squeeze().reshape(-1,1).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_1  = tar1.detach().squeeze().reshape(-1,1).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(pred, bins = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(pred, target_1, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(pct_shifted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(target_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_col(df_test_all, 'TGNA_2', 'pct_change_shifted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score(target_1, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=15\n",
    "out1[i], tar1[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tar1[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out1.squeeze().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tar1.squeeze().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tar1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out1.squeeze().detach().numpy()[99]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_i.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
